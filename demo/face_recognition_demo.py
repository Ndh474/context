"""
FUACS Face Recognition Demo v·ªõi Anti-Spoofing
- Face Detection: InsightFace buffalo_l
- Anti-Spoofing: Silent-Face-Anti-Spoofing (MiniFASNet)
- H·ªó tr·ª£: Webcam v√† RTSP camera

C√°ch ch·∫°y:
    python face_recognition_demo.py
"""

import cv2
import threading
import tkinter as tk
from tkinter import Label, Button, Frame, messagebox, Checkbutton, BooleanVar, Scale
from PIL import Image, ImageTk
import time
import numpy as np
import os
import sys

# ============================================
# C·∫§U H√åNH - THAY ƒê·ªîI ·ªû ƒê√ÇY
# ============================================
USE_WEBCAM = True  # True = webcam laptop, False = RTSP camera
RTSP_URL = "rtsp://admin:admin@192.168.0.228:8554/live"
WEBCAM_INDEX = 0  # 0 = webcam m·∫∑c ƒë·ªãnh

# ƒê∆∞·ªùng d·∫´n t·ªõi anti_spoof module
ANTISPOOF_DIR = os.path.join(os.path.dirname(__file__), "anti_spoof")

# ============================================
# IMPORT INSIGHTFACE
# ============================================
try:
    from insightface.app import FaceAnalysis
    INSIGHTFACE_AVAILABLE = True
except ImportError:
    INSIGHTFACE_AVAILABLE = False
    print("‚ö†Ô∏è Ch∆∞a c√†i insightface. Ch·∫°y: pip install insightface onnxruntime-gpu")

# ============================================
# IMPORT ANTI-SPOOFING MODULE
# ============================================
ANTISPOOF_AVAILABLE = False

try:
    from anti_spoof.models import MiniFASNetV1, MiniFASNetV2, MiniFASNetV1SE, MiniFASNetV2SE
    from anti_spoof.utils import parse_model_name, get_kernel, CropImage
    from anti_spoof.transform import Compose, ToTensor
    ANTISPOOF_AVAILABLE = True
    print("‚úÖ Anti-Spoofing module ƒë√£ s·∫µn s√†ng!")
except ImportError as e:
    print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ import anti_spoof: {e}")
    print("üí° C√†i ƒë·∫∑t: pip install torch torchvision")


class RTSPVideoStream:
    """ƒê·ªçc video stream trong thread ri√™ng ƒë·ªÉ tr√°nh lag GUI"""
    
    def __init__(self, src=0):
        self.src = src
        self.stream = None
        self.grabbed = False
        self.frame = None
        self.stop_event = False
        self.lock = threading.Lock()
        
    def start(self):
        t = threading.Thread(target=self.update, daemon=True)
        t.start()
        return self

    def update(self):
        print(f"üìπ ƒêang k·∫øt n·ªëi camera: {self.src}...")
        self.stream = cv2.VideoCapture(self.src)
        
        if self.stream.isOpened():
            self.stream.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            print("‚úÖ K·∫øt n·ªëi camera th√†nh c√¥ng!")
        else:
            print("‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi camera!")
            self.stop_event = True
            return

        while not self.stop_event:
            if not self.stream.isOpened():
                break
            grabbed, frame = self.stream.read()
            with self.lock:
                self.grabbed = grabbed
                self.frame = frame
            time.sleep(0.005)
        
        self.stream.release()

    def read(self):
        with self.lock:
            return self.frame.copy() if self.grabbed and self.frame is not None else None

    def stop(self):
        self.stop_event = True


class SilentFaceAntiSpoof:
    """
    Wrapper cho Anti-Spoofing module
    S·ª≠ d·ª•ng 2 model: MiniFASNetV2 v√† MiniFASNetV1SE
    """
    
    def __init__(self, device_id=0):
        self.available = False
        self.model_dir = ANTISPOOF_DIR
        self.device_id = device_id
        self.device = None
        self.models = {}  # Cache loaded models
        self.image_cropper = None
        self.threshold = 0.5
        
    def load(self):
        """T·∫£i model anti-spoofing"""
        if not ANTISPOOF_AVAILABLE:
            print("‚ùå Anti-Spoof module kh√¥ng kh·∫£ d·ª•ng")
            return False
            
        try:
            import torch
            print("üîÑ ƒêang t·∫£i Anti-Spoof models...")
            
            # Setup device
            self.device = torch.device(f"cuda:{self.device_id}" if torch.cuda.is_available() else "cpu")
            print(f"   Device: {self.device}")
            
            # Ki·ªÉm tra model files
            model_files = [f for f in os.listdir(self.model_dir) if f.endswith('.pth')]
            print(f"   Models: {model_files}")
            
            # Model mapping
            MODEL_MAPPING = {
                'MiniFASNetV1': MiniFASNetV1,
                'MiniFASNetV2': MiniFASNetV2,
                'MiniFASNetV1SE': MiniFASNetV1SE,
                'MiniFASNetV2SE': MiniFASNetV2SE
            }
            
            for model_name in model_files:
                h_input, w_input, model_type, scale = parse_model_name(model_name)
                kernel_size = get_kernel(h_input, w_input)
                
                model = MODEL_MAPPING[model_type](conv6_kernel=kernel_size).to(self.device)
                model_path = os.path.join(self.model_dir, model_name)
                
                state_dict = torch.load(model_path, map_location=self.device, weights_only=True)
                # Handle 'module.' prefix from DataParallel
                if list(state_dict.keys())[0].startswith('module.'):
                    from collections import OrderedDict
                    new_state_dict = OrderedDict()
                    for key, value in state_dict.items():
                        new_state_dict[key[7:]] = value
                    state_dict = new_state_dict
                
                model.load_state_dict(state_dict)
                model.eval()
                
                self.models[model_name] = {
                    'model': model,
                    'h_input': h_input,
                    'w_input': w_input,
                    'scale': scale
                }
                print(f"   ‚úì Loaded {model_name}")
            
            # Image cropper
            self.image_cropper = CropImage()
            
            self.available = True
            print("‚úÖ Anti-Spoof models ƒë√£ s·∫µn s√†ng!")
            return True
            
        except Exception as e:
            print(f"‚ùå L·ªói t·∫£i Anti-Spoof: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def check(self, frame, bbox=None):
        """
        Ki·ªÉm tra liveness c·ªßa khu√¥n m·∫∑t
        
        Args:
            frame: BGR image (numpy array)
            bbox: [x1, y1, x2, y2] t·ª´ InsightFace
            
        Returns:
            (is_real, score, label): 
                - is_real: True n·∫øu l√† khu√¥n m·∫∑t th·∫≠t
                - score: ƒëi·ªÉm s·ªë t·ª´ 0-1
                - label: "REAL" ho·∫∑c "FAKE"
        """
        if not self.available or not self.models:
            return True, 0.5, "N/A"
        
        if bbox is None:
            return True, 0.5, "N/A"
            
        try:
            import torch
            import torch.nn.functional as F
            
            # Convert bbox t·ª´ [x1, y1, x2, y2] sang [x, y, w, h]
            x1, y1, x2, y2 = [int(v) for v in bbox]
            image_bbox = [x1, y1, x2 - x1, y2 - y1]
            
            if image_bbox[2] <= 0 or image_bbox[3] <= 0:
                return True, 0.5, "N/A"
            
            # Ch·∫°y prediction v·ªõi t·∫•t c·∫£ models
            prediction = np.zeros((1, 3))
            test_transform = Compose([ToTensor()])
            
            for model_name, model_info in self.models.items():
                model = model_info['model']
                h_input = model_info['h_input']
                w_input = model_info['w_input']
                scale = model_info['scale']
                
                param = {
                    "org_img": frame,
                    "bbox": image_bbox,
                    "scale": scale,
                    "out_w": w_input,
                    "out_h": h_input,
                    "crop": True,
                }
                
                if scale is None:
                    param["crop"] = False
                    
                img = self.image_cropper.crop(**param)
                
                # Transform v√† predict
                img_tensor = test_transform(img)
                img_tensor = img_tensor.unsqueeze(0).to(self.device)
                
                with torch.no_grad():
                    result = model(img_tensor)
                    result = F.softmax(result, dim=1).cpu().numpy()
                
                prediction += result
            
            # T√≠nh k·∫øt qu·∫£ (chia cho s·ªë models)
            num_models = len(self.models)
            label_idx = np.argmax(prediction)
            score = prediction[0][label_idx] / num_models
            
            if label_idx == 1:
                is_real = True
                label = "REAL"
            else:
                is_real = False
                label = "FAKE"
                
            return is_real, float(score), label
            
        except Exception as e:
            print(f"Anti-spoof error: {e}")
            return True, 0.5, "ERR"


class App:
    def __init__(self, root, camera_source):
        self.root = root
        self.root.title("FUACS Demo - Face Recognition + Anti-Spoofing")
        self.root.geometry("1100x750")
        self.root.configure(bg="#2c3e50")

        self.camera_source = camera_source
        self.is_playing = True
        
        # --- AI Models ---
        self.face_detection_enabled = BooleanVar(value=False)
        self.anti_spoof_enabled = BooleanVar(value=False)
        self.face_model = None
        self.anti_spoof = SilentFaceAntiSpoof(device_id=0)
        
        # --- Smoothing buffer (l·∫•y trung b√¨nh N frame g·∫ßn nh·∫•t) ---
        self.spoof_history = []  # List of (is_real, score)
        self.SMOOTH_FRAMES = 5  # S·ªë frame ƒë·ªÉ l·∫•y trung b√¨nh
        
        # --- Statistics ---
        self.stats = {"real": 0, "fake": 0, "total": 0}
        
        # ============================================
        # GUI LAYOUT
        # ============================================
        
        # Control Panel (Bottom)
        self.control_frame = Frame(root, bg="#34495e", height=120)
        self.control_frame.pack(side=tk.BOTTOM, fill=tk.X)
        
        # Video Frame (Top)
        self.main_frame = Frame(root, bg="#2c3e50")
        self.main_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # Video Label
        self.video_label = Label(self.main_frame, bg="black", 
                                  text="ƒêang kh·ªüi t·∫°o...", fg="white", font=("Arial", 14))
        self.video_label.pack(fill=tk.BOTH, expand=True)
        
        # --- Control Row 1: Checkboxes ---
        row1 = Frame(self.control_frame, bg="#34495e")
        row1.pack(fill=tk.X, pady=5)
        
        # Face Detection checkbox
        self.chk_face = Checkbutton(
            row1, text="üîç Face Detection", 
            variable=self.face_detection_enabled,
            bg="#34495e", fg="white", selectcolor="#2c3e50",
            font=("Arial", 10, "bold"),
            activebackground="#34495e", activeforeground="white",
            state=tk.NORMAL if INSIGHTFACE_AVAILABLE else tk.DISABLED
        )
        self.chk_face.pack(side=tk.LEFT, padx=20)
        
        # Anti-Spoof checkbox
        self.chk_antispoof = Checkbutton(
            row1, text="üõ°Ô∏è Anti-Spoofing", 
            variable=self.anti_spoof_enabled,
            bg="#34495e", fg="white", selectcolor="#2c3e50",
            font=("Arial", 10, "bold"),
            activebackground="#34495e", activeforeground="white",
            state=tk.NORMAL if ANTISPOOF_AVAILABLE else tk.DISABLED
        )
        self.chk_antispoof.pack(side=tk.LEFT, padx=20)
        
        # Status label
        self.lbl_status = Label(row1, text="Status: ƒêang t·∫£i model...", 
                                 bg="#34495e", fg="#f39c12", font=("Arial", 10))
        self.lbl_status.pack(side=tk.RIGHT, padx=20)
        
        # --- Control Row 2: Stats ---
        row2 = Frame(self.control_frame, bg="#34495e")
        row2.pack(fill=tk.X, pady=5)
        
        # Stats labels
        self.lbl_stats = Label(row2, text="Real: 0 | Fake: 0 | Total: 0", 
                                bg="#34495e", fg="#3498db", font=("Arial", 10, "bold"))
        self.lbl_stats.pack(side=tk.LEFT, padx=20)
        
        # Reset stats button
        Button(row2, text="üîÑ Reset Stats", command=self.reset_stats,
               bg="#9b59b6", fg="white", font=("Arial", 9)).pack(side=tk.LEFT, padx=10)
        
        # --- Control Row 3: Buttons ---
        row3 = Frame(self.control_frame, bg="#34495e")
        row3.pack(fill=tk.X, pady=5)
        
        Button(row3, text="üì∏ Ch·ª•p ·∫¢nh", command=self.snapshot,
               bg="#27ae60", fg="white", font=("Arical", 10, "bold"),
               padx=15, pady=5).pack(side=tk.LEFT, padx=20)
        
        Button(row3, text="‚ùå Tho√°t", command=self.on_close,
               bg="#c0392b", fg="white", font=("Arial", 10, "bold"),
               padx=15, pady=5).pack(side=tk.RIGHT, padx=20)
        
        # Camera info
        cam_type = "Webcam" if USE_WEBCAM else "RTSP"
        Label(row3, text=f"üìπ {cam_type}: {camera_source}", 
              bg="#34495e", fg="#95a5a6", font=("Arial", 9)).pack(side=tk.RIGHT, padx=20)
        
        # ============================================
        # START THREADS
        # ============================================
        
        # Start video stream
        self.video_stream = RTSPVideoStream(self.camera_source).start()
        
        # Load AI models in background
        threading.Thread(target=self.init_models, daemon=True).start()
        
        # Start video update loop
        self.update_video()
    
    def init_models(self):
        """T·∫£i c√°c model AI trong background thread"""
        status_parts = []
        
        try:
            # 1. Face Detection model
            if INSIGHTFACE_AVAILABLE:
                print("üîÑ ƒêang t·∫£i Face Detection model (buffalo_l)...")
                self.face_model = FaceAnalysis(
                    name='buffalo_l',
                    providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
                )
                self.face_model.prepare(ctx_id=0, det_size=(640, 640))
                print("‚úÖ Face Detection model ƒë√£ s·∫µn s√†ng!")
                status_parts.append("Face ‚úì")
            else:
                status_parts.append("Face ‚úó")
            
            # 2. Anti-Spoof model
            if ANTISPOOF_AVAILABLE:
                if self.anti_spoof.load():
                    status_parts.append("AntiSpoof ‚úì")
                else:
                    status_parts.append("AntiSpoof ‚úó")
            else:
                status_parts.append("AntiSpoof ‚úó")
            
            # Update status
            status_text = "Status: " + " | ".join(status_parts)
            self.root.after(0, lambda: self.lbl_status.configure(
                text=status_text, fg="#27ae60"
            ))
            
        except Exception as e:
            print(f"‚ùå L·ªói t·∫£i model: {e}")
            import traceback
            traceback.print_exc()
            self.root.after(0, lambda: self.lbl_status.configure(
                text=f"Status: Error - {str(e)[:30]}", fg="#e74c3c"
            ))
    
    def reset_stats(self):
        """Reset th·ªëng k√™"""
        self.stats = {"real": 0, "fake": 0, "total": 0}
        self.lbl_stats.configure(text="Real: 0 | Fake: 0 | Total: 0")
    
    def update_video(self):
        """Main video update loop"""
        if not self.is_playing:
            return

        frame = self.video_stream.read()
        
        if frame is not None:
            display_frame = frame.copy()
            
            # Face Detection + Anti-Spoofing
            if self.face_detection_enabled.get() and self.face_model is not None:
                try:
                    faces = self.face_model.get(frame)
                    
                    for face in faces:
                        bbox = face.bbox.astype(int)
                        
                        # Anti-Spoofing check
                        if self.anti_spoof_enabled.get():
                            if not self.anti_spoof.available:
                                # Debug: model ch∆∞a s·∫µn s√†ng
                                color = (255, 165, 0)  # Orange = loading
                                display_label = "LOADING..."
                            else:
                                is_real, score, label = self.anti_spoof.check(frame, face.bbox)
                                
                                # Smoothing: l∆∞u k·∫øt qu·∫£ v√† l·∫•y trung b√¨nh
                                self.spoof_history.append((1 if is_real else 0, score))
                                if len(self.spoof_history) > self.SMOOTH_FRAMES:
                                    self.spoof_history.pop(0)
                                
                                # T√≠nh trung b√¨nh
                                avg_real = sum(h[0] for h in self.spoof_history) / len(self.spoof_history)
                                avg_score = sum(h[1] for h in self.spoof_history) / len(self.spoof_history)
                                
                                # Quy·∫øt ƒë·ªãnh d·ª±a tr√™n majority vote
                                is_real_smoothed = avg_real >= 0.5
                                
                                # Update stats (ch·ªâ ƒë·∫øm khi ƒë·ªß frames)
                                if len(self.spoof_history) >= self.SMOOTH_FRAMES:
                                    self.stats["total"] += 1
                                    if is_real_smoothed:
                                        self.stats["real"] += 1
                                        color = (0, 255, 0)  # Green = Real
                                        label = "REAL"
                                    else:
                                        self.stats["fake"] += 1
                                        color = (0, 0, 255)  # Red = Fake
                                        label = "FAKE"
                                else:
                                    color = (255, 165, 0)  # Orange = collecting
                                    label = "..."
                                
                                display_label = f"{label} {avg_score:.2f}"
                                
                                # Update stats label (throttled)
                                if self.stats["total"] % 5 == 0:
                                    self.lbl_stats.configure(
                                        text=f"Real: {self.stats['real']} | Fake: {self.stats['fake']} | Total: {self.stats['total']}"
                                    )
                        else:
                            color = (0, 255, 0)
                            display_label = f"{face.det_score:.2f}"
                        
                        # Draw bounding box
                        cv2.rectangle(display_frame, 
                                      (bbox[0], bbox[1]), (bbox[2], bbox[3]), 
                                      color, 2)
                        
                        # Draw label
                        cv2.putText(display_frame, display_label, 
                                    (bbox[0], bbox[1] - 10),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
                        
                        # Draw landmarks
                        if face.kps is not None:
                            for kp in face.kps.astype(int):
                                cv2.circle(display_frame, (kp[0], kp[1]), 2, (255, 0, 0), -1)
                                
                except Exception as e:
                    print(f"Detection error: {e}")
            
            # Convert to Tkinter image
            cv2image = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(cv2image)
            
            # Resize to fit window
            win_w = self.video_label.winfo_width()
            win_h = self.video_label.winfo_height()
            if win_w > 1 and win_h > 1:
                img = img.resize((win_w, win_h), Image.Resampling.LANCZOS)
            
            imgtk = ImageTk.PhotoImage(image=img)
            self.video_label.imgtk = imgtk
            self.video_label.configure(image=imgtk, text="")
        else:
            self.video_label.configure(text="üìπ ƒêang k·∫øt n·ªëi camera...", fg="white")
        
        self.root.after(15, self.update_video)
    
    def snapshot(self):
        """Ch·ª•p v√† l∆∞u ·∫£nh"""
        frame = self.video_stream.read()
        if frame is not None:
            filename = f"snapshot_{int(time.time())}.jpg"
            cv2.imwrite(filename, frame)
            messagebox.showinfo("Th√¥ng b√°o", f"ƒê√£ l∆∞u: {filename}")
        else:
            messagebox.showwarning("C·∫£nh b√°o", "Ch∆∞a c√≥ t√≠n hi·ªáu video!")
    
    def on_close(self):
        """ƒê√≥ng ·ª©ng d·ª•ng"""
        self.is_playing = False
        self.video_stream.stop()
        self.root.destroy()


if __name__ == "__main__":
    # Ch·ªçn ngu·ªìn camera
    camera_source = WEBCAM_INDEX if USE_WEBCAM else RTSP_URL
    
    print("=" * 50)
    print("FUACS Face Recognition Demo")
    print("=" * 50)
    print(f"Camera: {'Webcam' if USE_WEBCAM else 'RTSP'}")
    print(f"Source: {camera_source}")
    print(f"InsightFace: {'‚úì' if INSIGHTFACE_AVAILABLE else '‚úó'}")
    print(f"AntiSpoof: {'‚úì' if ANTISPOOF_AVAILABLE else '‚úó'}")
    print("=" * 50)
    
    root = tk.Tk()
    app = App(root, camera_source)
    root.protocol("WM_DELETE_WINDOW", app.on_close)
    root.mainloop()
