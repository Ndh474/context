# üéØ RECOGNITION SERVICE - H∆Ø·ªöNG D·∫™N CHI TI·∫æT LU·ªíNG ƒêI·ªÇM DANH

## M·ª•c l·ª•c

1. [T·ªïng quan ki·∫øn tr√∫c](#1-t·ªïng-quan-ki·∫øn-tr√∫c)
2. [Lu·ªìng ƒëi·ªÉm danh ch√≠nh](#2-lu·ªìng-ƒëi·ªÉm-danh-ch√≠nh)
3. [Chi ti·∫øt t·ª´ng b∆∞·ªõc x·ª≠ l√Ω](#3-chi-ti·∫øt-t·ª´ng-b∆∞·ªõc-x·ª≠-l√Ω)
4. [Thu·∫≠t to√°n nh·∫≠n di·ªán khu√¥n m·∫∑t](#4-thu·∫≠t-to√°n-nh·∫≠n-di·ªán-khu√¥n-m·∫∑t)
5. [C√°c ch·∫ø ƒë·ªô ƒëi·ªÉm danh](#5-c√°c-ch·∫ø-ƒë·ªô-ƒëi·ªÉm-danh)
6. [X·ª≠ l√Ω l·ªói v√† Edge Cases](#6-x·ª≠-l√Ω-l·ªói-v√†-edge-cases)
7. [C·∫•u h√¨nh v√† tham s·ªë](#7-c·∫•u-h√¨nh-v√†-tham-s·ªë)

---

## 1. T·ªïng quan ki·∫øn tr√∫c

### 1.1. V·ªã tr√≠ trong h·ªá th·ªëng

Recognition Service l√† microservice Python/FastAPI, ƒë√≥ng vai tr√≤ **"b·ªô n√£o AI"** c·ªßa h·ªá th·ªëng FUACS:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Frontend Web   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Java Backend   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Recognition Service ‚îÇ
‚îÇ   (Next.js)     ‚îÇ     ‚îÇ  (Spring Boot)   ‚îÇ     ‚îÇ    (FastAPI)        ‚îÇ
‚îÇ   Port: 3000    ‚îÇ     ‚îÇ   Port: 8080     ‚îÇ     ‚îÇ    Port: 8000       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ                         ‚îÇ
                               ‚îÇ                         ‚ñº
                               ‚îÇ                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                               ‚îÇ                  ‚îÇ  IP Cameras  ‚îÇ
                               ‚îÇ                  ‚îÇ   (RTSP)     ‚îÇ
                               ‚ñº                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ  PostgreSQL  ‚îÇ
                        ‚îÇ  + pgvector  ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.2. Nhi·ªám v·ª• ch√≠nh

- **Nh·∫≠n di·ªán khu√¥n m·∫∑t** t·ª´ video stream IP cameras
- **So kh·ªõp** v·ªõi database embeddings c·ªßa sinh vi√™n
- **G·ª≠i k·∫øt qu·∫£** v·ªÅ Java Backend qua callback API
- **L∆∞u b·∫±ng ch·ª©ng** (·∫£nh crop khu√¥n m·∫∑t)


---

## 2. Lu·ªìng ƒëi·ªÉm danh ch√≠nh

### 2.1. Sequence Diagram t·ªïng quan

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Lecturer ‚îÇ     ‚îÇ Java Backend ‚îÇ     ‚îÇ Recognition Svc   ‚îÇ     ‚îÇ IP Camera ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                  ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ 1. B·∫•m "B·∫Øt ƒë·∫ßu  ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ    ƒëi·ªÉm danh"    ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ                  ‚îÇ 2. POST /process-session                    ‚îÇ
     ‚îÇ                  ‚îÇ   (students, cameras, config)               ‚îÇ
     ‚îÇ                  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ                     ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ 3. Test RTSP        ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ                  ‚îÇ 4. Response: OK       ‚îÇ                     ‚îÇ
     ‚îÇ                  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                     ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ 5. UI: "ƒêang     ‚îÇ                       ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
     ‚îÇ    ƒëi·ªÉm danh..." ‚îÇ                       ‚îÇ ‚îÇ BACKGROUND LOOP ‚îÇ ‚îÇ
     ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                       ‚îÇ ‚îÇ                 ‚îÇ ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ ‚îÇ 6. Capture frame‚îÇ‚óÄ‚î§
     ‚îÇ                  ‚îÇ                       ‚îÇ ‚îÇ 7. Detect faces ‚îÇ ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ ‚îÇ 8. Match student‚îÇ ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ ‚îÇ 9. Save evidence‚îÇ ‚îÇ
     ‚îÇ                  ‚îÇ 10. Callback:         ‚îÇ ‚îÇ                 ‚îÇ ‚îÇ
     ‚îÇ                  ‚îÇ     recognition       ‚îÇ ‚îÇ                 ‚îÇ ‚îÇ
     ‚îÇ                  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ ‚îÇ                 ‚îÇ ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
     ‚îÇ 11. Realtime     ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ     update UI    ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ 12. B·∫•m "D·ª´ng"   ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ                  ‚îÇ 13. POST /stop-session‚îÇ                     ‚îÇ
     ‚îÇ                  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ                     ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ 14. Cancel tasks    ‚îÇ
     ‚îÇ                  ‚îÇ 15. Statistics        ‚îÇ     Cleanup         ‚îÇ
     ‚îÇ                  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                     ‚îÇ
     ‚îÇ 16. Hi·ªÉn th·ªã     ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ     k·∫øt qu·∫£      ‚îÇ                       ‚îÇ                     ‚îÇ
     ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                       ‚îÇ                     ‚îÇ
```

### 2.2. M√¥ t·∫£ ng·∫Øn g·ªçn

1. **Gi·∫£ng vi√™n** b·∫•m n√∫t "B·∫Øt ƒë·∫ßu ƒëi·ªÉm danh" tr√™n giao di·ªán web
2. **Java Backend** g·ªçi API `/process-session` ƒë·∫øn Recognition Service, g·ª≠i k√®m:
   - Danh s√°ch sinh vi√™n (k√®m embedding vectors)
   - Danh s√°ch cameras trong ph√≤ng
   - C·∫•u h√¨nh (ng∆∞·ª°ng similarity, scan interval, callback URL)
3. **Recognition Service** test k·∫øt n·ªëi t·∫•t c·∫£ cameras
4. N·∫øu √≠t nh·∫•t 1 camera OK ‚Üí b·∫Øt ƒë·∫ßu **background tasks** (1 task/camera)
5. M·ªói task ch·∫°y **v√≤ng l·∫∑p li√™n t·ª•c**:
   - Capture frame t·ª´ camera
   - Detect faces trong frame
   - So kh·ªõp v·ªõi embeddings sinh vi√™n
   - N·∫øu match ‚Üí g·ª≠i callback v·ªÅ Java Backend
6. **Java Backend** c·∫≠p nh·∫≠t database v√† push realtime ƒë·∫øn frontend
7. Khi gi·∫£ng vi√™n b·∫•m "D·ª´ng" ‚Üí g·ªçi `/stop-session` ƒë·ªÉ cleanup


---

## 3. Chi ti·∫øt t·ª´ng b∆∞·ªõc x·ª≠ l√Ω

### 3.1. B∆∞·ªõc 1: Nh·∫≠n request t·ª´ Java Backend

**Endpoint**: `POST /api/v1/recognition/process-session`

**Request body** (t·ª´ Java Backend):

```json
{
  "slotId": 123,
  "roomId": 5,
  "mode": "INITIAL",
  "callbackType": "REGULAR",
  "students": [
    {
      "userId": 1001,
      "fullName": "Nguy·ªÖn VƒÉn A",
      "rollNumber": "SE171234",
      "embeddingVector": [0.123, -0.456, 0.789, ...],  // 512 s·ªë th·ª±c
      "embeddingVersion": 1
    },
    {
      "userId": 1002,
      "fullName": "Tr·∫ßn Th·ªã B",
      "rollNumber": "SE171235",
      "embeddingVector": [0.234, -0.567, 0.890, ...],
      "embeddingVersion": 1
    }
  ],
  "cameras": [
    {
      "id": 1,
      "name": "Camera Tr∆∞·ªõc",
      "rtspUrl": "rtsp://admin:password@192.168.1.100:554/stream1"
    },
    {
      "id": 2,
      "name": "Camera Sau",
      "rtspUrl": "rtsp://admin:password@192.168.1.101:554/stream1"
    }
  ],
  "config": {
    "similarityThreshold": 0.55,
    "scanInterval": 3.0,
    "callbackUrl": "http://localhost:8080/api/internal/recognition/callback"
  }
}
```

**Code x·ª≠ l√Ω** (file `api/v1/recognition.py`):

```python
@router.post("/process-session", response_model=RecognitionResponse)
async def start_recognition_session(
    request: StartSessionRequest, 
    api_key: str = Depends(verify_api_key)  # B·∫Øt bu·ªôc c√≥ API key
):
    try:
        # G·ªçi service ƒë·ªÉ b·∫Øt ƒë·∫ßu session
        session_data = await recognition_service.start_session(request)
        
        return RecognitionResponse(
            status=200, 
            message="Face recognition session started successfully", 
            data=session_data
        )
    except ValueError as e:
        # Session ƒë√£ t·ªìn t·∫°i cho slot n√†y
        raise HTTPException(status_code=409, detail={
            "code": "SESSION_ALREADY_EXISTS",
            "message": f"Session already exists for slot {request.slotId}"
        })
    except RuntimeError as e:
        # T·∫•t c·∫£ cameras ƒë·ªÅu fail
        raise HTTPException(status_code=500, detail={
            "code": "ALL_CAMERAS_FAILED",
            "message": "Failed to connect to any camera"
        })
```

### 3.2. B∆∞·ªõc 2: Kh·ªüi t·∫°o Session

**Code** (file `services/recognition_service.py`):

```python
async def start_session(self, request: StartSessionRequest) -> SessionDataDTO:
    slot_id = request.slotId

    # 1. Ki·ªÉm tra session ƒë√£ t·ªìn t·∫°i ch∆∞a
    existing_session = await session_manager.get_session(slot_id)
    if existing_session:
        raise ValueError(f"Session already exists for slot {slot_id}")

    # 2. Test k·∫øt n·ªëi t·∫•t c·∫£ cameras song song
    camera_results = await self._test_cameras(request.cameras)

    # 3. ƒê·∫øm cameras th√†nh c√¥ng/th·∫•t b·∫°i
    active_cameras = sum(1 for r in camera_results if r["connected"])
    failed_cameras = len(camera_results) - active_cameras

    # 4. N·∫øu T·∫§T C·∫¢ cameras fail ‚Üí b√°o l·ªói
    if active_cameras == 0:
        raise RuntimeError("All cameras failed to connect")

    # 5. T·∫°o th∆∞ m·ª•c l∆∞u evidence
    evidence_dir = f"./uploads/evidence/{slot_id}"
    os.makedirs(evidence_dir, exist_ok=True)

    # 6. T·∫°o session state
    session_state = SessionState(
        slot_id=slot_id,
        room_id=request.roomId,
        mode=request.mode.value,
        callback_type=request.callbackType,
        total_students=len(request.students),
        active_cameras=active_cameras,
        started_at=datetime.now(pytz.timezone('Asia/Ho_Chi_Minh')),
        recognition_count=0
    )

    # 7. L∆∞u session v√†o memory
    await session_manager.add_session(slot_id, session_state)

    # 8. Kh·ªüi ƒë·ªông background tasks cho m·ªói camera ƒë√£ k·∫øt n·ªëi
    for i, camera in enumerate(request.cameras):
        if camera_results[i]["connected"]:
            task_id = f"slot_{slot_id}_camera_{camera.id}"
            coro = self._process_camera(
                slot_id=slot_id,
                camera=camera,
                students=request.students,
                config=request.config
            )
            await task_manager.start_task(task_id, coro)

    return SessionDataDTO(...)
```

**Gi·∫£i th√≠ch**:
- Session ƒë∆∞·ª£c l∆∞u **in-memory** (m·∫•t khi restart service)
- M·ªói camera ch·∫°y **1 async task ri√™ng bi·ªát** ‚Üí x·ª≠ l√Ω song song
- Ch·ªâ c·∫ßn **1 camera** k·∫øt n·ªëi th√†nh c√¥ng l√† c√≥ th·ªÉ b·∫Øt ƒë·∫ßu


### 3.3. B∆∞·ªõc 3: Test k·∫øt n·ªëi Camera (RTSP)

**Code** (file `services/rtsp_handler.py`):

```python
async def test_rtsp_connection(rtsp_url: str, timeout: int = 5) -> dict:
    """
    Test k·∫øt n·ªëi RTSP v√† tr·∫£ v·ªÅ th√¥ng tin camera
    """
    try:
        with RTSPHandler(rtsp_url, timeout) as handler:
            # L·∫•y ƒë·ªô ph√¢n gi·∫£i
            width, height = handler.get_resolution()
            
            # Capture 5 frames ƒë·ªÉ t√≠nh FPS
            frames, fps = handler.capture_frames(5)
            
            # ƒêo ƒë·ªô tr·ªÖ
            latency = handler.calculate_latency()
            
            return {
                "connected": True,
                "frameRate": fps,
                "resolution": {"width": width, "height": height},
                "latency": latency,
                "stability": "stable" if fps > 10 else "unstable"
            }
    except Exception as e:
        return {
            "connected": False,
            "error": str(e)
        }
```

**RTSPHandler class**:

```python
class RTSPHandler:
    def __init__(self, rtsp_url: str, timeout: int = 5):
        self.rtsp_url = rtsp_url
        self.timeout = timeout
        self.cap = None

    def connect(self) -> bool:
        # S·ª≠ d·ª•ng OpenCV ƒë·ªÉ k·∫øt n·ªëi RTSP
        self.cap = cv2.VideoCapture(self.rtsp_url, cv2.CAP_FFMPEG)
        self.cap.set(cv2.CAP_PROP_OPEN_TIMEOUT_MSEC, self.timeout * 1000)
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)  # Buffer nh·ªè ƒë·ªÉ l·∫•y frame m·ªõi nh·∫•t
        
        # Verify b·∫±ng c√°ch ƒë·ªçc 1 frame
        ret, frame = self.cap.read()
        if not ret:
            raise RTSPConnectionError("Failed to read frame")
        
        return True
```

**L∆∞u √Ω quan tr·ªçng**:
- S·ª≠ d·ª•ng **TCP transport** cho RTSP (·ªïn ƒë·ªãnh h∆°n UDP)
- Buffer size = 1 ƒë·ªÉ lu√¥n l·∫•y **frame m·ªõi nh·∫•t** (tr√°nh lag)
- Timeout 5 gi√¢y cho m·ªói camera

### 3.4. B∆∞·ªõc 4: Background Processing Loop

ƒê√¢y l√† **tr√°i tim** c·ªßa h·ªá th·ªëng - v√≤ng l·∫∑p x·ª≠ l√Ω li√™n t·ª•c cho m·ªói camera:

**Code** (file `services/recognition_service.py`):

```python
async def _process_camera(self, slot_id: int, camera, students, config):
    """
    Background task x·ª≠ l√Ω 1 camera
    Ch·∫°y li√™n t·ª•c cho ƒë·∫øn khi b·ªã cancel
    """
    try:
        # M·ªü k·∫øt n·ªëi camera
        cap = cv2.VideoCapture(camera.rtspUrl)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        if not cap.isOpened():
            logger.error(f"Failed to open camera {camera.id}")
            return

        scan_interval = config.scanInterval  # VD: 3 gi√¢y
        last_scan = datetime.now(pytz.timezone('Asia/Ho_Chi_Minh'))

        while True:
            # Ki·ªÉm tra task b·ªã cancel ch∆∞a
            if asyncio.current_task().cancelled():
                break
            
            # Ki·ªÉm tra session c√≤n t·ªìn t·∫°i kh√¥ng
            session_state = await session_manager.get_session(slot_id)
            if not session_state:
                break

            # ===== FLUSH BUFFER =====
            # B·ªè qua c√°c frame c≈© trong buffer ƒë·ªÉ l·∫•y frame m·ªõi nh·∫•t
            for _ in range(3):
                cap.grab()

            # ƒê·ªçc frame
            ret, frame = cap.read()
            if not ret or frame is None:
                await asyncio.sleep(1)
                continue

            # ===== KI·ªÇM TRA SCAN INTERVAL =====
            now = datetime.now(pytz.timezone('Asia/Ho_Chi_Minh'))
            if (now - last_scan).total_seconds() < scan_interval:
                await asyncio.sleep(0.1)
                continue

            last_scan = now

            # ===== X·ª¨ L√ù FRAME =====
            recognitions = await face_recognizer.process_frame(
                frame=frame,
                students=students,
                similarity_threshold=config.similarityThreshold,
                slot_id=slot_id,
                camera_id=camera.id,
                recognized_students=self.recognized_students[slot_id],
                callback_type=session.callback_type
            )

            # ===== G·ª¨I CALLBACK =====
            if recognitions:
                for recognition in recognitions:
                    student_id = recognition['studentUserId']
                    
                    # Th√™m v√†o set ƒë√£ nh·∫≠n di·ªán (deduplication)
                    self.recognized_students[slot_id].add(student_id)
                    
                    # G·ª≠i callback v·ªÅ Java Backend
                    await callback_service.send_recognition(
                        callback_url=config.callbackUrl,
                        slot_id=slot_id,
                        recognition=recognition,
                        mode=session.mode,
                        callback_type=session.callback_type
                    )
                    
                    # TƒÉng counter
                    await session_manager.increment_recognition_count(slot_id)

            # Ngh·ªâ ng·∫Øn ƒë·ªÉ kh√¥ng chi·∫øm CPU
            await asyncio.sleep(0.1)

    except asyncio.CancelledError:
        logger.info(f"Camera task cancelled: slot={slot_id}")
    finally:
        if cap:
            cap.release()  # Gi·∫£i ph√≥ng camera
```

**Gi·∫£i th√≠ch chi ti·∫øt**:

1. **Flush buffer**: Camera RTSP c√≥ buffer, n·∫øu kh√¥ng flush s·∫Ω x·ª≠ l√Ω frame c≈©
2. **Scan interval**: Kh√¥ng x·ª≠ l√Ω m·ªçi frame, ch·ªâ x·ª≠ l√Ω theo kho·∫£ng th·ªùi gian (VD: 3 gi√¢y/l·∫ßn)
3. **Deduplication**: M·ªói sinh vi√™n ch·ªâ ƒë∆∞·ª£c nh·∫≠n di·ªán 1 l·∫ßn per session
4. **Graceful shutdown**: Khi cancel, gi·∫£i ph√≥ng t√†i nguy√™n ƒë√∫ng c√°ch


### 3.5. B∆∞·ªõc 5: Nh·∫≠n di·ªán khu√¥n m·∫∑t trong Frame

**Code** (file `services/face_recognizer.py`):

```python
async def process_frame(
    self, 
    frame: np.ndarray,           # ·∫¢nh BGR t·ª´ OpenCV
    students: List[Any],          # Danh s√°ch sinh vi√™n v·ªõi embeddings
    similarity_threshold: float,  # Ng∆∞·ª°ng match (VD: 0.55)
    slot_id: int,
    camera_id: int,
    recognized_students: set,     # Set sinh vi√™n ƒë√£ nh·∫≠n di·ªán (deduplication)
    callback_type: str = "REGULAR"
) -> List[Dict]:
    """
    X·ª≠ l√Ω 1 frame ƒë·ªÉ nh·∫≠n di·ªán khu√¥n m·∫∑t
    
    Returns: Danh s√°ch c√°c recognition results
    """
    recognitions = []

    # ===== 1. DETECT FACES =====
    # InsightFace tr·∫£ v·ªÅ list c√°c face objects
    faces = self.face_app.get(frame)

    if not faces:
        return []  # Kh√¥ng c√≥ m·∫∑t n√†o trong frame

    # ===== 2. X·ª¨ L√ù T·ª™NG KHU√îN M·∫∂T =====
    for face in faces:
        # L·∫•y embedding 512 chi·ªÅu (ƒë√£ normalize)
        face_embedding = face.normed_embedding

        # ===== 3. T√åM BEST MATCH =====
        best_match = self._find_best_match(
            face_embedding, 
            students, 
            similarity_threshold
        )

        if best_match:
            student_id = best_match['userId']

            # ===== 4. DEDUPLICATION CHECK =====
            if student_id in recognized_students:
                continue  # ƒê√£ nh·∫≠n di·ªán r·ªìi, b·ªè qua

            # ===== 5. CROP V√Ä L∆ØU EVIDENCE =====
            bbox = face.bbox.astype(int)
            x1, y1, x2, y2 = bbox
            
            # Th√™m padding ƒë·ªÉ ·∫£nh ƒë·∫πp h∆°n
            padding = 50
            h, w = frame.shape[:2]
            x1 = max(0, x1 - padding)
            y1 = max(0, y1 - padding)
            x2 = min(w, x2 + padding)
            y2 = min(h, y2 + padding)
            
            face_crop = frame[y1:y2, x1:x2]
            
            # Resize n·∫øu qu√° nh·ªè (t·ªëi thi·ªÉu 300x300)
            min_size = 300
            if face_crop.shape[0] < min_size or face_crop.shape[1] < min_size:
                scale = max(min_size / face_crop.shape[0], min_size / face_crop.shape[1])
                face_crop = cv2.resize(face_crop, None, fx=scale, fy=scale)

            # L∆∞u evidence
            evidence_path = self._save_evidence(
                face_crop, slot_id, student_id, 
                best_match["rollNumber"], callback_type
            )

            # ===== 6. T·∫†O RECOGNITION RESULT =====
            recognition = {
                "studentUserId": student_id,
                "confidence": best_match["similarity"],
                "timestamp": get_utc_timestamp_for_java(),
                "cameraId": camera_id,
                "evidence": {
                    "regularImageUrl": evidence_path if callback_type == "REGULAR" else None,
                    "examImageUrl": evidence_path if callback_type == "EXAM" else None
                }
            }
            recognitions.append(recognition)

    return recognitions
```

**Gi·∫£i th√≠ch**:
- **InsightFace** detect t·∫•t c·∫£ khu√¥n m·∫∑t trong frame
- M·ªói face c√≥ `normed_embedding` (vector 512 chi·ªÅu ƒë√£ chu·∫©n h√≥a)
- So s√°nh v·ªõi **T·∫§T C·∫¢** sinh vi√™n ƒë·ªÉ t√¨m best match
- Crop khu√¥n m·∫∑t + padding ƒë·ªÉ l∆∞u l√†m b·∫±ng ch·ª©ng


---

## 4. Thu·∫≠t to√°n nh·∫≠n di·ªán khu√¥n m·∫∑t

### 4.1. InsightFace v√† Model buffalo_l

**InsightFace** l√† th∆∞ vi·ªán face recognition m√£ ngu·ªìn m·ªü, s·ª≠ d·ª•ng deep learning.

**Model buffalo_l** bao g·ªìm:
- **Detection**: SCRFD (Sample and Computation Redistribution for Face Detection)
  - Input: 640x640 pixels
  - Output: Bounding boxes + landmarks
- **Recognition**: ArcFace v·ªõi backbone ResNet100
  - Output: Vector 512 chi·ªÅu (embedding)

**C√°ch load model**:

```python
from insightface.app import FaceAnalysis

# Kh·ªüi t·∫°o v·ªõi auto-detect GPU/CPU
face_app = FaceAnalysis(
    name='buffalo_l',           # T√™n model
    providers=['CUDAExecutionProvider', 'CPUExecutionProvider']  # GPU tr∆∞·ªõc, fallback CPU
)

# Chu·∫©n b·ªã model
face_app.prepare(
    ctx_id=0,           # 0 = GPU, -1 = CPU
    det_size=(640, 640) # K√≠ch th∆∞·ªõc detection
)
```

### 4.2. Cosine Similarity - Thu·∫≠t to√°n so kh·ªõp

**C√¥ng th·ª©c**:

```
                    A ¬∑ B
similarity = ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
              ||A|| √ó ||B||
```

Trong ƒë√≥:
- `A ¬∑ B` = dot product (t√≠ch v√¥ h∆∞·ªõng)
- `||A||` = norm (ƒë·ªô d√†i vector)

**√ù nghƒ©a**:
- K·∫øt qu·∫£ t·ª´ -1 ƒë·∫øn 1
- 1 = ho√†n to√†n gi·ªëng nhau (c√πng h∆∞·ªõng)
- 0 = kh√¥ng li√™n quan (vu√¥ng g√≥c)
- -1 = ho√†n to√†n ng∆∞·ª£c nhau

**Code implementation**:

```python
def _cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
    """T√≠nh cosine similarity gi·ªØa 2 vectors"""
    dot_product = np.dot(vec1, vec2)      # T√≠ch v√¥ h∆∞·ªõng
    norm1 = np.linalg.norm(vec1)          # ƒê·ªô d√†i vector 1
    norm2 = np.linalg.norm(vec2)          # ƒê·ªô d√†i vector 2

    if norm1 == 0 or norm2 == 0:
        return 0.0

    return dot_product / (norm1 * norm2)
```

### 4.3. T√¨m Best Match

**Code**:

```python
def _find_best_match(
    self, 
    face_embedding: np.ndarray,  # Embedding t·ª´ camera (512-dim)
    students: List[Any],          # Danh s√°ch sinh vi√™n
    threshold: float              # Ng∆∞·ª°ng (VD: 0.55)
) -> Optional[Dict]:
    """
    T√¨m sinh vi√™n kh·ªõp nh·∫•t v·ªõi khu√¥n m·∫∑t detected
    """
    best_match = None
    best_similarity = 0

    # So s√°nh v·ªõi T·∫§T C·∫¢ sinh vi√™n
    for student in students:
        student_embedding = np.array(student.embeddingVector)

        # Ki·ªÉm tra dimension
        if face_embedding.shape[0] != student_embedding.shape[0]:
            continue  # Skip n·∫øu kh√¥ng kh·ªõp dimension

        # T√≠nh similarity
        similarity = self._cosine_similarity(face_embedding, student_embedding)

        # C·∫≠p nh·∫≠t best match
        if similarity > best_similarity:
            best_similarity = similarity
            
            # Ch·ªâ ch·∫•p nh·∫≠n n·∫øu v∆∞·ª£t ng∆∞·ª°ng
            if similarity >= threshold:
                best_match = {
                    "userId": student.userId,
                    "fullName": student.fullName,
                    "rollNumber": student.rollNumber,
                    "similarity": float(similarity),
                }

    return best_match
```

### 4.4. Ng∆∞·ª°ng Similarity (Threshold)

**√ù nghƒ©a c√°c m·ª©c ng∆∞·ª°ng**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Ng∆∞·ª°ng    ‚îÇ                      √ù nghƒ©a                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ    0.40     ‚îÇ R·∫•t th·∫•p - nhi·ªÅu false positive (nh·∫≠n nh·∫ßm)         ‚îÇ
‚îÇ    0.50     ‚îÇ Th·∫•p - c√≥ th·ªÉ nh·∫≠n nh·∫ßm ng∆∞·ªùi gi·ªëng nhau            ‚îÇ
‚îÇ    0.55     ‚îÇ M·∫∑c ƒë·ªãnh - c√¢n b·∫±ng gi·ªØa accuracy v√† recall         ‚îÇ
‚îÇ    0.60     ‚îÇ Cao - √≠t false positive, c√≥ th·ªÉ miss m·ªôt s·ªë ng∆∞·ªùi   ‚îÇ
‚îÇ    0.70     ‚îÇ R·∫•t cao - ch·ªâ match khi r·∫•t ch·∫Øc ch·∫Øn               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**C√°ch ch·ªçn ng∆∞·ª°ng**:
- **ƒêi·ªÉm danh th∆∞·ªùng**: 0.55 (c√¢n b·∫±ng)
- **Thi c·ª≠**: 0.60-0.65 (nghi√™m ng·∫∑t h∆°n)
- **M√¥i tr∆∞·ªùng √°nh s√°ng k√©m**: 0.50 (n·ªõi l·ªèng)


---

## 5. C√°c ch·∫ø ƒë·ªô ƒëi·ªÉm danh

### 5.1. Scan Mode: INITIAL vs RESCAN

**INITIAL** (L·∫ßn ƒë·∫ßu):
- Qu√©t t·∫•t c·∫£ sinh vi√™n trong l·ªõp
- M·ª•c ƒë√≠ch: ƒêi·ªÉm danh ban ƒë·∫ßu

**RESCAN** (Qu√©t l·∫°i):
- Ch·ªâ qu√©t nh·ªØng sinh vi√™n **ch∆∞a c√≥ m·∫∑t** t·ª´ l·∫ßn INITIAL
- M·ª•c ƒë√≠ch: Cho sinh vi√™n ƒë·∫øn mu·ªôn c∆° h·ªôi ƒëi·ªÉm danh

```python
class ScanMode(str, Enum):
    INITIAL = "INITIAL"
    RESCAN = "RESCAN"
```

**Lu·ªìng s·ª≠ d·ª•ng**:

```
1. Gi·∫£ng vi√™n b·∫Øt ƒë·∫ßu ƒëi·ªÉm danh (INITIAL)
   ‚Üí Qu√©t 5 ph√∫t
   ‚Üí K·∫øt qu·∫£: 25/30 sinh vi√™n c√≥ m·∫∑t

2. Gi·∫£ng vi√™n b·∫•m "Qu√©t l·∫°i" (RESCAN)
   ‚Üí Java Backend g·ª≠i request v·ªõi mode=RESCAN
   ‚Üí Ch·ªâ g·ª≠i 5 sinh vi√™n ch∆∞a c√≥ m·∫∑t
   ‚Üí Qu√©t th√™m 2 ph√∫t
   ‚Üí K·∫øt qu·∫£: Th√™m 3 sinh vi√™n
```

### 5.2. Callback Type: REGULAR vs EXAM

**REGULAR** (ƒêi·ªÉm danh th∆∞·ªùng):
- D√πng cho bu·ªïi h·ªçc b√¨nh th∆∞·ªùng
- Callback route ƒë·∫øn b·∫£ng `lecture_attendance`
- Evidence l∆∞u v√†o `regularImageUrl`

**EXAM** (ƒêi·ªÉm danh thi):
- D√πng cho bu·ªïi thi
- Callback route ƒë·∫øn b·∫£ng `exam_attendance`
- Evidence l∆∞u v√†o `examImageUrl`
- Th∆∞·ªùng c√≥ ng∆∞·ª°ng similarity cao h∆°n

```python
# Trong recognition result
recognition = {
    "studentUserId": student_id,
    "confidence": 0.87,
    "evidence": {
        # Ch·ªâ 1 trong 2 c√≥ gi√° tr·ªã, t√πy callback_type
        "regularImageUrl": "http://.../evidence/123/1001_SE171234.jpg",
        "examImageUrl": None
    }
}
```

### 5.3. Callback Format g·ª≠i v·ªÅ Java Backend

**Endpoint**: `POST {callbackUrl}` (VD: `http://localhost:8080/api/internal/recognition/callback`)

**Headers**:
```
Content-Type: application/json
X-API-Key: python-service-secret-key-12345
```

**Request Body**:

```json
{
  "slotId": 123,
  "mode": "INITIAL",
  "callbackType": "REGULAR",
  "recognitions": [
    {
      "studentUserId": 1001,
      "confidence": 0.87,
      "timestamp": "2024-12-08T10:30:00Z",
      "cameraId": 1,
      "evidence": {
        "regularImageUrl": "http://localhost:8000/uploads/evidence/123/1001_SE171234.jpg",
        "examImageUrl": null
      }
    }
  ]
}
```

**Code g·ª≠i callback**:

```python
async def send_recognition(
    self,
    callback_url: str,
    slot_id: int,
    recognition: Dict[str, Any],
    mode: str = "INITIAL",
    callback_type: str = "REGULAR"
) -> bool:
    headers = {
        "Content-Type": "application/json",
        "X-API-Key": settings.API_KEY
    }

    body = {
        "slotId": slot_id,
        "mode": mode,
        "callbackType": callback_type,
        "recognitions": [recognition]
    }

    # Retry logic v·ªõi exponential backoff
    for attempt in range(3):
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    callback_url,
                    json=body,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status == 200:
                        return True
        except Exception as e:
            logger.warning(f"Callback failed: attempt {attempt + 1}")
        
        # Exponential backoff: 1s, 2s, 4s
        await asyncio.sleep(self.retry_delay * (2 ** attempt))

    return False
```


---

## 6. X·ª≠ l√Ω l·ªói v√† Edge Cases

### 6.1. Camera Connection Failures

**T√¨nh hu·ªëng**: M·ªôt s·ªë cameras kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c

**X·ª≠ l√Ω**:
- Test t·∫•t c·∫£ cameras **song song** (parallel)
- N·∫øu **√≠t nh·∫•t 1 camera** OK ‚Üí b·∫Øt ƒë·∫ßu session
- N·∫øu **T·∫§T C·∫¢ cameras** fail ‚Üí b√°o l·ªói, kh√¥ng b·∫Øt ƒë·∫ßu

```python
async def _test_cameras(self, cameras) -> List[Dict]:
    """Test t·∫•t c·∫£ cameras song song"""
    tasks = [test_rtsp_connection(cam.rtspUrl) for cam in cameras]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    camera_results = []
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            camera_results.append({"connected": False, "error": str(result)})
            logger.warning(f"Camera {cameras[i].name} failed: {result}")
        else:
            camera_results.append(result)
    
    return camera_results
```

### 6.2. Callback Failures v√† Auto-Stop

**T√¨nh hu·ªëng**: Java Backend kh√¥ng ph·∫£n h·ªìi (down, network issue)

**X·ª≠ l√Ω**:
- Retry 3 l·∫ßn v·ªõi exponential backoff (1s ‚Üí 2s ‚Üí 4s)
- N·∫øu **10 callbacks li√™n ti·∫øp** fail ‚Üí auto-stop session
- N·∫øu **2 ph√∫t** kh√¥ng c√≥ callback th√†nh c√¥ng ‚Üí auto-stop session

```python
# Trong _process_camera()
MAX_CONSECUTIVE_FAILURES = 10
MAX_FAILURE_DURATION = 120  # 2 ph√∫t

async def _should_auto_stop(self, slot_id: int) -> bool:
    # Ki·ªÉm tra s·ªë l·∫ßn fail li√™n ti·∫øp
    failures = self.callback_failures.get(slot_id, 0)
    if failures >= MAX_CONSECUTIVE_FAILURES:
        return True
    
    # Ki·ªÉm tra th·ªùi gian t·ª´ l·∫ßn th√†nh c√¥ng cu·ªëi
    last_success = self.last_success_time.get(slot_id)
    if last_success:
        duration = (datetime.now() - last_success).seconds
        if duration >= MAX_FAILURE_DURATION:
            return True
    
    return False
```

### 6.3. Deduplication - Tr√°nh ƒëi·ªÉm danh tr√πng

**T√¨nh hu·ªëng**: Sinh vi√™n xu·∫•t hi·ªán nhi·ªÅu l·∫ßn trong camera

**X·ª≠ l√Ω**:
- M·ªói session c√≥ 1 **Set** l∆∞u student IDs ƒë√£ nh·∫≠n di·ªán
- Tr∆∞·ªõc khi g·ª≠i callback, ki·ªÉm tra student ƒë√£ trong Set ch∆∞a
- N·∫øu ƒë√£ c√≥ ‚Üí skip, kh√¥ng g·ª≠i callback

```python
# Kh·ªüi t·∫°o
self.recognized_students: Dict[int, set] = {}  # slot_id -> set(student_ids)

# Trong process_frame()
if student_id in recognized_students:
    logger.debug(f"Student {student_id} already recognized, skipping")
    continue

# Sau khi g·ª≠i callback th√†nh c√¥ng
self.recognized_students[slot_id].add(student_id)
```

### 6.4. Session Already Exists

**T√¨nh hu·ªëng**: G·ªçi start session khi session ƒë√£ ƒëang ch·∫°y

**X·ª≠ l√Ω**: Tr·∫£ v·ªÅ HTTP 409 Conflict

```python
existing_session = await session_manager.get_session(slot_id)
if existing_session:
    raise HTTPException(
        status_code=409,
        detail={
            "code": "SESSION_ALREADY_EXISTS",
            "message": f"Session already exists for slot {slot_id}"
        }
    )
```

### 6.5. Frame Capture Failures

**T√¨nh hu·ªëng**: Camera b·ªã ng·∫Øt k·∫øt n·ªëi gi·ªØa ch·ª´ng

**X·ª≠ l√Ω**:
- Log warning v√† retry sau 1 gi√¢y
- Kh√¥ng crash task, ti·∫øp t·ª•c v√≤ng l·∫∑p

```python
ret, frame = cap.read()
if not ret or frame is None:
    logger.warning(f"Failed to read frame from camera {camera.id}")
    await asyncio.sleep(1)
    continue  # Th·ª≠ l·∫°i
```

### 6.6. No Face Detected

**T√¨nh hu·ªëng**: Frame kh√¥ng c√≥ khu√¥n m·∫∑t n√†o

**X·ª≠ l√Ω**: ƒê∆°n gi·∫£n return empty list, kh√¥ng log (tr√°nh spam)

```python
faces = self.face_app.get(frame)
if not faces:
    return []  # Kh√¥ng c√≥ m·∫∑t, return r·ªóng
```


---

## 7. C·∫•u h√¨nh v√† tham s·ªë

### 7.1. Environment Variables

File `.env` trong `recognition-service/`:

```bash
# ===== SERVICE IDENTITY =====
SERVICE_NAME=FUACS Face Recognition Service
SERVICE_VERSION=1.0.0

# ===== SECURITY =====
# API Key d√πng chung gi·ªØa Java Backend v√† Python Service
API_KEY=python-service-secret-key-12345

# ===== JAVA BACKEND INTEGRATION =====
JAVA_BACKEND_URL=http://localhost:8080

# ===== INSIGHTFACE MODEL =====
MODEL_NAME=buffalo_l
MODEL_PATH=./src/recognition_service/models/insightface

# ===== SERVER =====
HOST=0.0.0.0          # Bind t·∫•t c·∫£ interfaces
PORT=8000
PUBLIC_HOST=localhost  # Hostname cho URL generation (evidence images)
LOG_LEVEL=INFO

# ===== RECOGNITION SETTINGS =====
DEFAULT_SIMILARITY_THRESHOLD=0.55   # Ng∆∞·ª°ng match m·∫∑c ƒë·ªãnh
MAX_SCAN_INTERVAL=60                # T·ªëi ƒëa 60 gi√¢y gi·ªØa c√°c scan
EVIDENCE_RETENTION_DAYS=30          # Gi·ªØ evidence 30 ng√†y

# ===== CALLBACK SETTINGS =====
CALLBACK_TIMEOUT=30                 # Timeout 30 gi√¢y
CALLBACK_RETRY_ATTEMPTS=3           # Retry 3 l·∫ßn

# ===== EMBEDDING GENERATION =====
EMBEDDING_QUALITY_THRESHOLD=0.50    # Ng∆∞·ª°ng ch·∫•t l∆∞·ª£ng t·ªëi thi·ªÉu
```

### 7.2. Request Parameters chi ti·∫øt

#### StartSessionRequest

```python
class StartSessionRequest(BaseModel):
    slotId: int                    # ID c·ªßa slot (bu·ªïi h·ªçc/thi)
    roomId: int                    # ID ph√≤ng h·ªçc
    mode: ScanMode                 # INITIAL ho·∫∑c RESCAN
    callbackType: str              # "REGULAR" ho·∫∑c "EXAM"
    students: List[StudentDTO]     # Danh s√°ch sinh vi√™n (min 1)
    cameras: List[CameraDTO]       # Danh s√°ch cameras (min 1)
    config: SessionConfigDTO       # C·∫•u h√¨nh session
```

#### SessionConfigDTO

```python
class SessionConfigDTO(BaseModel):
    similarityThreshold: float = 0.55   # Ng∆∞·ª°ng match (0.0 - 1.0)
    scanInterval: float = 1.5           # Gi√¢y gi·ªØa c√°c scan (0.5 - 60)
    callbackUrl: str                    # URL callback v·ªÅ Java Backend
```

**Gi·∫£i th√≠ch c√°c tham s·ªë**:

- **similarityThreshold**: 
  - Gi√° tr·ªã t·ª´ 0.0 ƒë·∫øn 1.0
  - C√†ng cao ‚Üí c√†ng nghi√™m ng·∫∑t, √≠t false positive nh∆∞ng c√≥ th·ªÉ miss
  - C√†ng th·∫•p ‚Üí c√†ng d·ªÖ match, nhi·ªÅu false positive
  - Recommend: 0.55 cho ƒëi·ªÉm danh th∆∞·ªùng, 0.60-0.65 cho thi

- **scanInterval**:
  - Kho·∫£ng th·ªùi gian (gi√¢y) gi·ªØa c√°c l·∫ßn x·ª≠ l√Ω frame
  - Gi√° tr·ªã nh·ªè (0.5s) ‚Üí ph·∫£n h·ªìi nhanh, t·ªën CPU/GPU
  - Gi√° tr·ªã l·ªõn (5s) ‚Üí ti·∫øt ki·ªám t√†i nguy√™n, ph·∫£n h·ªìi ch·∫≠m
  - Recommend: 1.5-3 gi√¢y cho ƒëi·ªÉm danh th∆∞·ªùng

- **callbackUrl**:
  - URL endpoint c·ªßa Java Backend ƒë·ªÉ nh·∫≠n k·∫øt qu·∫£
  - Format: `http://{host}:{port}/api/internal/recognition/callback`

#### StudentEmbeddingDTO

```python
class StudentEmbeddingDTO(BaseModel):
    userId: int                              # ID user trong database
    fullName: str                            # H·ªç t√™n ƒë·∫ßy ƒë·ªß
    rollNumber: str                          # M√£ s·ªë sinh vi√™n (VD: SE171234)
    embeddingVector: List[float]             # Vector 512 chi·ªÅu
    embeddingVersion: int                    # Version c·ªßa embedding
```

#### CameraDTO

```python
class CameraDTO(BaseModel):
    id: int                    # ID camera trong database
    name: str                  # T√™n camera (VD: "Camera Tr∆∞·ªõc")
    rtspUrl: str               # URL RTSP stream
```

**Format RTSP URL**:
```
rtsp://{username}:{password}@{ip}:{port}/{path}

V√≠ d·ª•:
rtsp://admin:Admin123@192.168.1.100:554/Streaming/Channels/101
```

### 7.3. Response Format

#### Khi start session th√†nh c√¥ng

```json
{
  "status": 200,
  "message": "Face recognition session started successfully",
  "data": {
    "slotId": 123,
    "roomId": 5,
    "mode": "INITIAL",
    "totalStudents": 30,
    "totalCameras": 2,
    "activeCameras": 2,
    "failedCameras": 0,
    "sessionStartedAt": "2024-12-08T10:00:00Z"
  }
}
```

#### Khi stop session

```json
{
  "status": 200,
  "message": "Face recognition session stopped successfully",
  "data": {
    "slotId": 123,
    "roomId": 5,
    "mode": "INITIAL",
    "totalStudents": 30,
    "totalCameras": 2,
    "activeCameras": 2,
    "failedCameras": 0,
    "sessionStartedAt": "2024-12-08T10:00:00Z",
    "sessionStoppedAt": "2024-12-08T10:15:00Z",
    "sessionDuration": 900,
    "totalRecognitions": 28,
    "recognizedStudentIds": [1001, 1002, 1003, ...]
  }
}
```

### 7.4. Hardware Auto-Detection

Service t·ª± ƒë·ªông detect GPU/CPU v√† c·∫•u h√¨nh ph√π h·ª£p:

```python
class HardwareDetector:
    @staticmethod
    def detect_nvidia_gpu() -> bool:
        """Ki·ªÉm tra c√≥ NVIDIA GPU kh√¥ng"""
        try:
            result = subprocess.run(["nvidia-smi"], capture_output=True)
            return result.returncode == 0
        except FileNotFoundError:
            return False

    @staticmethod
    def detect_cuda() -> bool:
        """Ki·ªÉm tra CUDA c√≥ s·∫µn kh√¥ng"""
        cuda_path = os.environ.get("CUDA_PATH")
        return cuda_path and os.path.exists(cuda_path)

    @classmethod
    def get_optimal_config(cls) -> Dict:
        has_gpu = cls.detect_nvidia_gpu()
        has_cuda = cls.detect_cuda()

        if has_gpu and has_cuda:
            return {
                "device_type": "gpu",
                "providers": ["CUDAExecutionProvider", "CPUExecutionProvider"],
                "ctx_id": 0,  # GPU device 0
            }
        else:
            return {
                "device_type": "cpu",
                "providers": ["CPUExecutionProvider"],
                "ctx_id": -1,  # CPU
            }
```

**Hi·ªáu nƒÉng**:
- **GPU (CUDA)**: ~50-100ms per frame
- **CPU**: ~500-1000ms per frame
- GPU nhanh h∆°n **~10 l·∫ßn**


---

## 8. Lu·ªìng ƒëƒÉng k√Ω khu√¥n m·∫∑t (Embedding Generation)

### 8.1. T·ªïng quan

Tr∆∞·ªõc khi ƒëi·ªÉm danh ƒë∆∞·ª£c, sinh vi√™n c·∫ßn **ƒëƒÉng k√Ω khu√¥n m·∫∑t** ƒë·ªÉ t·∫°o embedding vector l∆∞u v√†o database.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Student  ‚îÇ     ‚îÇ Java Backend ‚îÇ     ‚îÇ Recognition Svc   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                  ‚îÇ                       ‚îÇ
     ‚îÇ 1. Upload ·∫£nh    ‚îÇ                       ‚îÇ
     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ                       ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ
     ‚îÇ                  ‚îÇ 2. POST /embeddings/generate
     ‚îÇ                  ‚îÇ    (photo file)       ‚îÇ
     ‚îÇ                  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ 3. Detect face
     ‚îÇ                  ‚îÇ                       ‚îÇ 4. Extract embedding
     ‚îÇ                  ‚îÇ                       ‚îÇ 5. Calculate quality
     ‚îÇ                  ‚îÇ                       ‚îÇ
     ‚îÇ                  ‚îÇ 6. Response:          ‚îÇ
     ‚îÇ                  ‚îÇ    embedding vector   ‚îÇ
     ‚îÇ                  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ
     ‚îÇ                  ‚îÇ 7. Save to PostgreSQL ‚îÇ
     ‚îÇ                  ‚îÇ    (pgvector)         ‚îÇ
     ‚îÇ                  ‚îÇ                       ‚îÇ
     ‚îÇ 8. Success       ‚îÇ                       ‚îÇ
     ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ                       ‚îÇ
```

### 8.2. API Endpoint

**Endpoint**: `POST /api/v1/embeddings/generate`

**Request**: `multipart/form-data`
- `photo`: File ·∫£nh (JPG/PNG)
- `submissionId`: ID c·ªßa identity submission

**Response**:

```json
{
  "status": 200,
  "message": "Face embedding generated successfully",
  "data": {
    "submissionId": 456,
    "embeddingVector": [0.123, -0.456, 0.789, ...],  // 512 s·ªë
    "quality": 0.85,
    "faceDetected": true,
    "processingTime": 0.45
  }
}
```

### 8.3. Quality Metrics

H·ªá th·ªëng t√≠nh **4 metrics** ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng ·∫£nh:

```python
class QualityAnalyzer:
    def calculate_metrics(self, frame, face) -> dict:
        # 1. FACE SIZE (30% weight)
        # T·ª∑ l·ªá khu√¥n m·∫∑t so v·ªõi frame
        # Target: >= 20% di·ªán t√≠ch frame
        face_area = (x2 - x1) * (y2 - y1)
        frame_area = frame_h * frame_w
        face_size_score = min(face_area / frame_area / 0.20, 1.0)

        # 2. CLARITY (25% weight)
        # ƒê·ªô s·∫Øc n√©t (Laplacian variance)
        gray = cv2.cvtColor(face_crop, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        clarity_score = min(laplacian_var / 500.0, 1.0)

        # 3. LIGHTING (25% weight)
        # ƒê·ªô s√°ng + contrast
        brightness = np.mean(gray)  # Ideal: 100-150
        contrast = np.std(gray)     # Ideal: > 40
        brightness_score = 1.0 - abs(brightness - 125) / 125
        contrast_score = min(contrast / 50.0, 1.0)
        lighting_score = (brightness_score + contrast_score) / 2

        # 4. FACE ANGLE (20% weight)
        # ƒê·ªô ch√≠nh di·ªán (d√πng detection confidence)
        face_angle_score = min(face.det_score, 1.0)

        return {
            "faceSize": face_size_score,
            "clarity": clarity_score,
            "lighting": lighting_score,
            "faceAngle": face_angle_score
        }

    def calculate_overall_quality(self, metrics) -> float:
        weights = {
            "faceSize": 0.30,
            "clarity": 0.25,
            "lighting": 0.25,
            "faceAngle": 0.20
        }
        return sum(metrics[k] * weights[k] for k in weights)
```

**Ng∆∞·ª°ng ch·∫•t l∆∞·ª£ng**: `>= 0.50` (c√≥ th·ªÉ c·∫•u h√¨nh)

### 8.4. C√°c l·ªói c√≥ th·ªÉ x·∫£y ra

```python
# 1. Kh√¥ng detect ƒë∆∞·ª£c m·∫∑t
class FaceNotDetectedError(Exception):
    code = "NO_FACE_IN_PHOTO"
    message = "No face detected in the provided photo."

# 2. Nhi·ªÅu h∆°n 1 m·∫∑t
class FaceNotDetectedError(Exception):
    code = "MULTIPLE_FACES_DETECTED"
    message = "Multiple faces detected. Please ensure only one person is in the photo."

# 3. Ch·∫•t l∆∞·ª£ng qu√° th·∫•p
class LowQualityError(Exception):
    code = "LOW_QUALITY_FACE"
    message = "Face quality too low. Please take photo in better lighting."
```

---

## 9. Evidence Storage (L∆∞u b·∫±ng ch·ª©ng)

### 9.1. C·∫•u tr√∫c th∆∞ m·ª•c

```
uploads/
‚îî‚îÄ‚îÄ evidence/
    ‚îú‚îÄ‚îÄ 123/                          # slot_id
    ‚îÇ   ‚îú‚îÄ‚îÄ 1001_SE171234.jpg        # user_id_rollNumber.jpg
    ‚îÇ   ‚îú‚îÄ‚îÄ 1002_SE171235.jpg
    ‚îÇ   ‚îî‚îÄ‚îÄ 1003_SE171236_exam.jpg   # C√≥ postfix _exam cho thi
    ‚îî‚îÄ‚îÄ 124/
        ‚îî‚îÄ‚îÄ ...
```

### 9.2. URL Format

```
http://{PUBLIC_HOST}:{PORT}/uploads/evidence/{slot_id}/{user_id}_{roll_number}.jpg

V√≠ d·ª•:
http://localhost:8000/uploads/evidence/123/1001_SE171234.jpg
```

### 9.3. Code l∆∞u evidence

```python
def _save_evidence(self, face_crop, slot_id, user_id, roll_number, callback_type):
    # T·∫°o filename
    if callback_type == "EXAM":
        filename = f"{user_id}_{roll_number}_exam.jpg"
    else:
        filename = f"{user_id}_{roll_number}.jpg"

    # T·∫°o th∆∞ m·ª•c
    evidence_dir = f"./uploads/evidence/{slot_id}"
    os.makedirs(evidence_dir, exist_ok=True)

    # L∆∞u ·∫£nh v·ªõi ch·∫•t l∆∞·ª£ng cao nh·∫•t
    filepath = os.path.join(evidence_dir, filename)
    cv2.imwrite(filepath, face_crop, [cv2.IMWRITE_JPEG_QUALITY, 100])

    # Tr·∫£ v·ªÅ URL ƒë·∫ßy ƒë·ªß
    settings = get_settings()
    base_url = f"http://{settings.PUBLIC_HOST}:{settings.PORT}"
    return f"{base_url}/uploads/evidence/{slot_id}/{filename}"
```

---

## 10. T·ªïng k·∫øt - ƒêi·ªÉm quan tr·ªçng khi b·∫£o v·ªá

### 10.1. Ki·∫øn tr√∫c
- Microservice ƒë·ªôc l·∫≠p, giao ti·∫øp qua REST API
- Async/await cho t·∫•t c·∫£ I/O operations
- Singleton pattern cho c√°c services

### 10.2. Thu·∫≠t to√°n
- **InsightFace** v·ªõi model **buffalo_l** (ArcFace + SCRFD)
- Embedding **512 chi·ªÅu**
- **Cosine similarity** ƒë·ªÉ so kh·ªõp
- Ng∆∞·ª°ng m·∫∑c ƒë·ªãnh **0.55**

### 10.3. X·ª≠ l√Ω song song
- M·ªói camera ch·∫°y **1 async task ri√™ng**
- Test cameras **parallel** khi start session
- Kh√¥ng block main thread

### 10.4. ƒê·ªô tin c·∫≠y
- **Deduplication**: M·ªói sinh vi√™n ch·ªâ ƒëi·ªÉm danh 1 l·∫ßn/session
- **Retry logic**: 3 l·∫ßn v·ªõi exponential backoff
- **Auto-stop**: T·ª± d·ª´ng khi backend kh√¥ng ph·∫£n h·ªìi
- **Graceful shutdown**: Cleanup ƒë√∫ng c√°ch khi stop

### 10.5. B·∫£o m·∫≠t
- **API Key authentication** cho t·∫•t c·∫£ protected endpoints
- Shared secret gi·ªØa Java Backend v√† Python Service

### 10.6. Hi·ªáu nƒÉng
- **GPU**: ~50-100ms/frame (recommend)
- **CPU**: ~500-1000ms/frame
- Scan interval c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh (0.5s - 60s)

---

## 11. C√¢u h·ªèi th∆∞·ªùng g·∫∑p khi b·∫£o v·ªá

**Q: T·∫°i sao ch·ªçn InsightFace thay v√¨ c√°c th∆∞ vi·ªán kh√°c?**
- Open source, mi·ªÖn ph√≠
- Accuracy cao (state-of-the-art)
- H·ªó tr·ª£ c·∫£ GPU v√† CPU
- Model buffalo_l ƒë√£ ƒë∆∞·ª£c train tr√™n dataset l·ªõn

**Q: Cosine similarity ho·∫°t ƒë·ªông nh∆∞ th·∫ø n√†o?**
- ƒêo g√≥c gi·ªØa 2 vectors trong kh√¥ng gian 512 chi·ªÅu
- Gi√° tr·ªã 1 = ho√†n to√†n gi·ªëng, 0 = kh√¥ng li√™n quan
- Kh√¥ng ph·ª• thu·ªôc v√†o ƒë·ªô d√†i vector (ƒë√£ normalize)

**Q: L√†m sao x·ª≠ l√Ω khi nhi·ªÅu sinh vi√™n xu·∫•t hi·ªán c√πng l√∫c?**
- InsightFace detect T·∫§T C·∫¢ faces trong frame
- X·ª≠ l√Ω t·ª´ng face m·ªôt c√°ch ƒë·ªôc l·∫≠p
- M·ªói face ƒë∆∞·ª£c so kh·ªõp v·ªõi to√†n b·ªô database

**Q: T·∫°i sao c·∫ßn deduplication?**
- Sinh vi√™n c√≥ th·ªÉ xu·∫•t hi·ªán nhi·ªÅu l·∫ßn trong camera
- Tr√°nh g·ª≠i nhi·ªÅu callbacks cho c√πng 1 ng∆∞·ªùi
- Ti·∫øt ki·ªám bandwidth v√† database operations

**Q: L√†m sao ƒë·∫£m b·∫£o l·∫•y frame m·ªõi nh·∫•t t·ª´ camera?**
- Set buffer size = 1
- Flush buffer tr∆∞·ªõc khi ƒë·ªçc frame
- S·ª≠ d·ª•ng TCP transport cho RTSP (·ªïn ƒë·ªãnh h∆°n UDP)

**Q: T·∫°i sao session l∆∞u in-memory thay v√¨ database?**
- Performance: Kh√¥ng c·∫ßn query database m·ªói frame
- Simplicity: Kh√¥ng c·∫ßn sync state
- Trade-off: M·∫•t session khi restart (acceptable cho use case n√†y)
