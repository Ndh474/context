{
  "metadata": {
    "codebase": "recognition-service",
    "category": "script",
    "generated_at": "2025-11-28T09:26:42.080395",
    "total_files": 1,
    "total_lines": 247,
    "total_bytes": 7782
  },
  "files": [
    {
      "path": "D:\\Work\\do_an_fall25\\fuacs\\recognition-service\\scripts\\setup.py",
      "relative_path": "scripts/setup.py",
      "filename": "setup.py",
      "size_bytes": 7782,
      "lines": 247,
      "last_modified": "2025-11-28T08:37:05.486559",
      "encoding": "utf-8",
      "language": "python",
      "content": "#!/usr/bin/env python3\n\"\"\"\nHardware Detection and Automatic Setup Script\nDetects GPU/CPU and installs appropriate dependencies\n\"\"\"\n\nimport subprocess\nimport sys\nimport os\nimport platform\nfrom pathlib import Path\n\n\ndef check_nvidia_gpu():\n    \"\"\"Check if NVIDIA GPU is available\"\"\"\n    try:\n        # Try nvidia-smi command\n        result = subprocess.run([\"nvidia-smi\"], capture_output=True, text=True, timeout=10)\n        if result.returncode == 0:\n            print(\"‚úì NVIDIA GPU detected via nvidia-smi\")\n            return True\n    except (subprocess.TimeoutExpired, FileNotFoundError):\n        pass\n\n    try:\n        # Try nvidia-ml-py (if available)\n        import pynvml\n\n        pynvml.nvmlInit()\n        gpu_count = pynvml.nvmlDeviceGetCount()\n        if gpu_count > 0:\n            print(f\"‚úì NVIDIA GPU detected via pynvml: {gpu_count} GPU(s)\")\n            return True\n    except ImportError:\n        pass\n    except Exception:\n        pass\n\n    print(\"‚úó No NVIDIA GPU detected\")\n    return False\n\n\ndef check_cuda_available():\n    \"\"\"Check if CUDA is available\"\"\"\n    try:\n        # Check if CUDA toolkit is installed\n        result = subprocess.run([\"nvcc\", \"--version\"], capture_output=True, text=True, timeout=10)\n        if result.returncode == 0:\n            print(\"‚úì CUDA toolkit detected\")\n            return True\n    except (subprocess.TimeoutExpired, FileNotFoundError):\n        pass\n\n    # Check CUDA environment variables\n    cuda_path = os.environ.get(\"CUDA_PATH\") or os.environ.get(\"CUDA_HOME\")\n    if cuda_path and os.path.exists(cuda_path):\n        print(f\"‚úì CUDA path detected: {cuda_path}\")\n        return True\n\n    print(\"‚úó CUDA toolkit not detected\")\n    return False\n\n\ndef detect_hardware():\n    \"\"\"Detect available hardware and return recommended configuration\"\"\"\n    print(\"=\" * 60)\n    print(\"üîç Hardware Detection\")\n    print(\"=\" * 60)\n\n    system_info = {\n        \"platform\": platform.system(),\n        \"architecture\": platform.architecture()[0],\n        \"processor\": platform.processor(),\n        \"python_version\": sys.version,\n    }\n\n    print(f\"Platform: {system_info['platform']} {system_info['architecture']}\")\n    print(f\"Processor: {system_info['processor']}\")\n    print(f\"Python: {sys.version.split()[0]}\")\n    print()\n\n    has_nvidia_gpu = check_nvidia_gpu()\n    has_cuda = check_cuda_available()\n\n    # Determine recommended setup\n    if has_nvidia_gpu and has_cuda:\n        recommendation = \"gpu\"\n        print(\"üöÄ Recommendation: GPU-accelerated setup\")\n        print(\"   - ONNX Runtime GPU\")\n        print(\"   - CUDA-enabled InsightFace\")\n    else:\n        recommendation = \"cpu\"\n        print(\"üñ•Ô∏è  Recommendation: CPU-only setup\")\n        print(\"   - ONNX Runtime CPU\")\n        print(\"   - CPU-optimized InsightFace\")\n\n    print(\"=\" * 60)\n    return recommendation, system_info\n\n\ndef update_pyproject_toml(hardware_type):\n    \"\"\"Update pyproject.toml with appropriate dependencies\"\"\"\n    print(f\"üìù Updating pyproject.toml for {hardware_type.upper()} setup...\")\n\n    pyproject_path = Path(\"pyproject.toml\")\n    if not pyproject_path.exists():\n        print(\"‚ùå pyproject.toml not found!\")\n        return False\n\n    # Read current content\n    with open(pyproject_path, \"r\", encoding=\"utf-8\") as f:\n        content = f.read()\n\n    # Replace onnxruntime dependency based on hardware\n    if hardware_type == \"gpu\":\n        # Use GPU version\n        content = content.replace('onnxruntime = \"^1.17.0\"', 'onnxruntime-gpu = \"^1.17.0\"').replace(\n            'onnxruntime-gpu = \"^1.17.0\"', 'onnxruntime-gpu = \"^1.17.0\"'  # Keep if already GPU\n        )\n        print(\"   ‚úì Set onnxruntime-gpu dependency\")\n    else:\n        # Use CPU version\n        content = content.replace('onnxruntime-gpu = \"^1.17.0\"', 'onnxruntime = \"^1.17.0\"').replace(\n            'onnxruntime = \"^1.17.0\"', 'onnxruntime = \"^1.17.0\"'  # Keep if already CPU\n        )\n        print(\"   ‚úì Set onnxruntime (CPU) dependency\")\n\n    # Write updated content\n    with open(pyproject_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(content)\n\n    print(\"   ‚úì pyproject.toml updated successfully\")\n    return True\n\n\ndef install_dependencies():\n    \"\"\"Install dependencies using Poetry\"\"\"\n    print(\"üì¶ Installing dependencies...\")\n\n    try:\n        # Check if poetry is available\n        result = subprocess.run([\"poetry\", \"--version\"], capture_output=True, text=True)\n        if result.returncode != 0:\n            print(\"‚ùå Poetry not found! Please install Poetry first:\")\n            print(\"   curl -sSL https://install.python-poetry.org | python3 -\")\n            return False\n\n        print(f\"   ‚úì Poetry detected: {result.stdout.strip()}\")\n\n        # Install dependencies\n        print(\"   Installing dependencies (this may take a few minutes)...\")\n        result = subprocess.run([\"poetry\", \"install\"], capture_output=True, text=True)\n\n        if result.returncode == 0:\n            print(\"   ‚úì Dependencies installed successfully\")\n            return True\n        else:\n            print(f\"   ‚ùå Installation failed: {result.stderr}\")\n            return False\n\n    except FileNotFoundError:\n        print(\"‚ùå Poetry not found! Please install Poetry first:\")\n        print(\"   curl -sSL https://install.python-poetry.org | python3 -\")\n        return False\n\n\ndef create_hardware_config(hardware_type, system_info):\n    \"\"\"Create hardware configuration file\"\"\"\n    config_dir = Path(\"src/recognition_service/config\")\n    config_dir.mkdir(parents=True, exist_ok=True)\n\n    config_path = config_dir / \"hardware.py\"\n\n    config_content = f'''\"\"\"\nHardware Configuration\nAuto-generated by setup script\n\"\"\"\n\n# Hardware detection results\nHARDWARE_TYPE = \"{hardware_type}\"\nSYSTEM_INFO = {system_info}\n\n# ONNX Runtime configuration\nif HARDWARE_TYPE == \"gpu\":\n    ONNX_PROVIDERS = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n    INSIGHTFACE_CTX_ID = 0  # GPU device 0\n    DEVICE_NAME = \"GPU (CUDA)\"\nelse:\n    ONNX_PROVIDERS = [\"CPUExecutionProvider\"]\n    INSIGHTFACE_CTX_ID = -1  # CPU\n    DEVICE_NAME = \"CPU\"\n\nprint(f\"üîß Hardware Config: {{DEVICE_NAME}} mode\")\n'''\n\n    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(config_content)\n\n    print(f\"   ‚úì Hardware config saved: {config_path}\")\n\n\ndef main():\n    \"\"\"Main setup function\"\"\"\n    print(\"üöÄ FUACS Face Recognition Service - Hardware Setup\")\n    print()\n\n    # Detect hardware\n    hardware_type, system_info = detect_hardware()\n\n    # Ask user for confirmation\n    print()\n    response = input(f\"Proceed with {hardware_type.upper()} setup? [Y/n]: \").strip().lower()\n    if response and response not in [\"y\", \"yes\"]:\n        print(\"Setup cancelled.\")\n        return\n\n    print()\n    print(\"üîß Setting up project...\")\n\n    # Update pyproject.toml\n    if not update_pyproject_toml(hardware_type):\n        print(\"‚ùå Failed to update pyproject.toml\")\n        return\n\n    # Create hardware config\n    create_hardware_config(hardware_type, system_info)\n\n    # Install dependencies\n    if not install_dependencies():\n        print(\"‚ùå Failed to install dependencies\")\n        return\n\n    print()\n    print(\"=\" * 60)\n    print(\"‚úÖ Setup completed successfully!\")\n    print(\"=\" * 60)\n    print()\n    print(\"Next steps:\")\n    print(\"1. Configure environment: cp .env.example .env\")\n    print(\"2. Start service: poetry run uvicorn src.recognition_service.main:app --reload\")\n    print()\n    print(f\"Hardware configuration: {hardware_type.upper()} mode\")\n    print(\"=\" * 60)\n\n\nif __name__ == \"__main__\":\n    main()\n"
    }
  ]
}