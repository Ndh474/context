{
  "metadata": {
    "codebase": "recognition-service",
    "category": "uncategorized",
    "generated_at": "2025-11-24T20:05:17.527879",
    "total_files": 4,
    "total_lines": 227,
    "total_bytes": 7861
  },
  "files": [
    {
      "path": "D:\\Work\\do_an_fall25\\fuacs\\recognition-service\\src\\recognition_service\\__init__.py",
      "relative_path": "src/recognition_service/__init__.py",
      "filename": "__init__.py",
      "size_bytes": 0,
      "lines": 0,
      "last_modified": "2025-10-05T13:04:14.657642",
      "encoding": "utf-8",
      "language": "python",
      "content": ""
    },
    {
      "path": "D:\\Work\\do_an_fall25\\fuacs\\recognition-service\\src\\recognition_service\\api\\__init__.py",
      "relative_path": "src/recognition_service/api/__init__.py",
      "filename": "__init__.py",
      "size_bytes": 34,
      "lines": 1,
      "last_modified": "2025-10-28T10:59:59.204556",
      "encoding": "utf-8",
      "language": "python",
      "content": "\"\"\"API package initialization\"\"\"\n"
    },
    {
      "path": "D:\\Work\\do_an_fall25\\fuacs\\recognition-service\\src\\recognition_service\\config\\hardware.py",
      "relative_path": "src/recognition_service/config/hardware.py",
      "filename": "hardware.py",
      "size_bytes": 732,
      "lines": 20,
      "last_modified": "2025-11-16T19:47:13.701543",
      "encoding": "utf-8",
      "language": "python",
      "content": "\"\"\"\nHardware Configuration\nAuto-generated by setup script\n\"\"\"\n\n# Hardware detection results\nHARDWARE_TYPE = \"gpu\"\nSYSTEM_INFO = {'platform': 'Windows', 'architecture': '64bit', 'processor': 'Intel64 Family 6 Model 151 Stepping 5, GenuineIntel', 'python_version': '3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]'}\n\n# ONNX Runtime configuration\nif HARDWARE_TYPE == \"gpu\":\n    ONNX_PROVIDERS = [\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n    INSIGHTFACE_CTX_ID = 0  # GPU device 0\n    DEVICE_NAME = \"GPU (CUDA)\"\nelse:\n    ONNX_PROVIDERS = [\"CPUExecutionProvider\"]\n    INSIGHTFACE_CTX_ID = -1  # CPU\n    DEVICE_NAME = \"CPU\"\n\nprint(f\"ðŸ”§ Hardware Config: {DEVICE_NAME} mode\")\n"
    },
    {
      "path": "D:\\Work\\do_an_fall25\\fuacs\\recognition-service\\src\\recognition_service\\main.py",
      "relative_path": "src/recognition_service/main.py",
      "filename": "main.py",
      "size_bytes": 7095,
      "lines": 206,
      "last_modified": "2025-11-22T23:56:46.786942",
      "encoding": "utf-8",
      "language": "python",
      "content": "\"\"\"\nFUACS Face Recognition Service\n\nFastAPI application providing face detection and recognition capabilities.\n\nEndpoints:\n- GET /api/v1/health - Health check (public)\n- GET /api/v1/metrics - Performance metrics (protected)\n- GET /api/v1/cameras/test-connection - Test camera (protected)\n- GET /api/v1/cameras/capture-frame - Capture frame (protected)\n- POST /api/v1/embeddings/validate - Validate video quality (protected)\n- POST /api/v1/embeddings/generate - Generate embedding (protected)\n\nFuture endpoints (separate tasks):\n- POST /api/v1/recognition/process-session - Start recognition\n- POST /api/v1/recognition/stop-session - Stop recognition\n\"\"\"\n\nfrom fastapi import FastAPI, Request\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.exceptions import RequestValidationError\nfrom fastapi.responses import JSONResponse\nfrom fastapi.staticfiles import StaticFiles\nfrom contextlib import asynccontextmanager\nimport logging\nimport json\nimport os\n\nfrom recognition_service.core.config import get_settings\nfrom recognition_service.core.logging_config import setup_logging\nfrom recognition_service.api.v1 import health, metrics, cameras, embeddings, recognition\nfrom recognition_service.services.model_loader import load_insightface_model\n\n# Initialize settings and logging\nsettings = get_settings()\nsetup_logging(settings.LOG_LEVEL)\nlogger = logging.getLogger(__name__)\n\n\n@asynccontextmanager\nasync def lifespan(app: FastAPI):\n    \"\"\"\n    Application lifespan manager.\n\n    Startup:\n    - Log service information\n    - Load InsightFace model\n    - Initialize global resources\n\n    Shutdown:\n    - Cleanup resources\n    - Log shutdown\n    \"\"\"\n    # ========== STARTUP ==========\n    from recognition_service.core.hardware import get_device_info\n\n    logger.info(f\"Starting {settings.SERVICE_NAME} v{settings.SERVICE_VERSION}\")\n    logger.info(f\"Server: {settings.HOST}:{settings.PORT} | Hardware: {get_device_info()} | Log: {settings.LOG_LEVEL}\")\n\n    # Load InsightFace model\n    try:\n        await load_insightface_model()\n    except Exception as e:\n        logger.error(f\"Failed to load InsightFace model: {e}\")\n        logger.warning(\"Service starting without model - recognition endpoints will fail\")\n\n    logger.info(\"Service ready to accept requests\")\n\n    yield  # Application runs here\n\n    # ========== SHUTDOWN ==========\n    logger.info(\"Shutting down service...\")\n\n    # Stop all active recognition sessions\n    from recognition_service.services.task_manager import task_manager\n    from recognition_service.services.session_manager import session_manager\n\n    try:\n        stopped_tasks = await task_manager.stop_all_tasks()\n        active_count = session_manager.active_sessions_count\n        session_manager._sessions.clear()\n        logger.info(f\"Cleanup complete: {stopped_tasks} tasks, {active_count} sessions cleared\")\n    except Exception as e:\n        logger.error(f\"Error during cleanup: {e}\")\n\n    logger.info(\"Service shutdown complete\")\n\n\n# Create FastAPI application\napp = FastAPI(\n    title=settings.SERVICE_NAME,\n    version=settings.SERVICE_VERSION,\n    description=\"Face Recognition Service using InsightFace\",\n    lifespan=lifespan,\n    docs_url=\"/docs\",  # Swagger UI\n    redoc_url=\"/redoc\",  # ReDoc UI\n)\n\n# CORS Middleware\n# Allow Spring Boot backend to call Python backend\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\n        settings.JAVA_BACKEND_URL,\n        \"http://localhost:8080\",\n        \"http://localhost:3000\",\n        \"http://localhost:8000\",  # Frontend dev\n    ],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n\n# Custom exception handler for request validation errors\n@app.exception_handler(RequestValidationError)\nasync def validation_exception_handler(request: Request, exc: RequestValidationError):\n    \"\"\"\n    Custom handler for request validation errors.\n    Logs detailed information about the failed request for debugging.\n    \"\"\"\n    logger.error(\"=\" * 80)\n    logger.error(\"REQUEST VALIDATION ERROR - DEBUGGING INFO\")\n    logger.error(\"=\" * 80)\n\n    # Log request details\n    logger.error(f\"Method: {request.method}\")\n    logger.error(f\"URL: {request.url}\")\n    logger.error(f\"Headers: {dict(request.headers)}\")\n    logger.error(f\"Query params: {dict(request.query_params)}\")\n    logger.error(f\"Path params: {dict(request.path_params)}\")\n\n    # Try to read and log the raw request body\n    try:\n        body = await request.body()\n        logger.error(f\"Raw body length: {len(body)} bytes\")\n        if body:\n            try:\n                # Try to decode as UTF-8\n                body_str = body.decode(\"utf-8\")\n                logger.error(f\"Raw body (string): {body_str}\")\n\n                # Try to parse as JSON\n                try:\n                    body_json = json.loads(body_str)\n                    logger.error(f\"Raw body (parsed JSON): {json.dumps(body_json, indent=2)}\")\n                except json.JSONDecodeError:\n                    logger.error(\"Raw body is not valid JSON\")\n            except UnicodeDecodeError:\n                logger.error(f\"Raw body (hex): {body.hex()}\")\n        else:\n            logger.error(\"Raw body is EMPTY or NULL\")\n    except Exception as e:\n        logger.error(f\"Failed to read request body: {e}\")\n\n    # Log validation errors\n    logger.error(f\"Validation errors: {exc.errors()}\")\n    logger.error(\"=\" * 80)\n\n    # Return standard 422 error response\n    return JSONResponse(\n        status_code=422,\n        content={\n            \"detail\": exc.errors(),\n            \"message\": \"Request validation failed - check server logs for detailed debugging info\",\n        },\n    )\n\n\n# Mount static files for evidence images\n# This must be done BEFORE including routers to avoid route conflicts\nuploads_dir = \"./uploads\"\nos.makedirs(uploads_dir, exist_ok=True)\napp.mount(\"/uploads\", StaticFiles(directory=uploads_dir), name=\"uploads\")\n\n# Include API routers\napp.include_router(health.router, prefix=\"/api/v1\", tags=[\"Health\"])\napp.include_router(metrics.router, prefix=\"/api/v1\", tags=[\"Metrics\"])\napp.include_router(cameras.router, prefix=\"/api/v1\", tags=[\"Cameras\"])\napp.include_router(embeddings.router, prefix=\"/api/v1\", tags=[\"Embeddings\"])\napp.include_router(recognition.router, prefix=\"/api/v1/recognition\", tags=[\"Recognition\"])\n\n\n@app.get(\"/\", tags=[\"Root\"])\nasync def root():\n    \"\"\"Root endpoint - service information\"\"\"\n    return {\n        \"service\": settings.SERVICE_NAME,\n        \"version\": settings.SERVICE_VERSION,\n        \"status\": \"running\",\n        \"docs\": \"/docs\",\n        \"health\": \"/api/v1/health\",\n    }\n\n\n# Run with: uvicorn src.recognition_service.main:app --reload --port 8000\nif __name__ == \"__main__\":\n    import uvicorn\n\n    uvicorn.run(\n        \"main:app\",\n        host=settings.HOST,\n        port=settings.PORT,\n        reload=settings.RELOAD,\n        log_level=settings.LOG_LEVEL.lower(),\n    )\n"
    }
  ]
}